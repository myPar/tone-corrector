{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8370de9-6a28-431f-95c4-1fcb9a771023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:47:34.324678Z",
     "iopub.status.busy": "2025-04-09T03:47:34.324350Z",
     "iopub.status.idle": "2025-04-09T03:47:42.094856Z",
     "shell.execute_reply": "2025-04-09T03:47:42.094191Z",
     "shell.execute_reply.started": "2025-04-09T03:47:34.324657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertConfig\n",
    "import os\n",
    "\n",
    "\n",
    "def load_llm(models_dir: str, model_name: str, tokenizer_name: str,\n",
    "             model_hub: str):\n",
    "    full_model_path = os.path.join(models_dir, model_name)\n",
    "    full_tokenizer_path = os.path.join(models_dir, tokenizer_name)\n",
    "\n",
    "    if os.path.isdir(full_model_path):\n",
    "        print(\"model is already saved, so load it locally from disk\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(full_model_path,\n",
    "                                                                   torchscript=True)\n",
    "    else:\n",
    "        config = BertConfig.from_pretrained(model_hub)\n",
    "        config.num_labels = 2\n",
    "        config.return_dict = True\n",
    "        config.torchscript=True\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_hub,\n",
    "                                                                   config=config,\n",
    "                                                                   ignore_mismatched_sizes=True)\n",
    "        for param in model.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        model.save_pretrained(full_model_path)\n",
    "\n",
    "\n",
    "    if os.path.isdir(full_tokenizer_path):\n",
    "        print(\"tokenizer is already saved, so load it locally from disk\")\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(full_tokenizer_path)\n",
    "    else:\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(model_hub)\n",
    "        tokenizer.save_pretrained(full_tokenizer_path)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f6f462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:47:58.569318Z",
     "iopub.status.busy": "2025-04-09T03:47:58.568940Z",
     "iopub.status.idle": "2025-04-09T03:48:11.005809Z",
     "shell.execute_reply": "2025-04-09T03:48:11.005118Z",
     "shell.execute_reply.started": "2025-04-09T03:47:58.569286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from datasets.arrow_dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56741fb",
   "metadata": {},
   "source": [
    "##### 1. Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366b6024-2819-47bd-bd7b-e350abdd5c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:21.430755Z",
     "iopub.status.busy": "2025-04-09T03:48:21.430103Z",
     "iopub.status.idle": "2025-04-09T03:48:21.434613Z",
     "shell.execute_reply": "2025-04-09T03:48:21.433697Z",
     "shell.execute_reply.started": "2025-04-09T03:48:21.430728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models_dir = \"new_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5eddbdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:24.089719Z",
     "iopub.status.busy": "2025-04-09T03:48:24.089410Z",
     "iopub.status.idle": "2025-04-09T03:48:31.498365Z",
     "shell.execute_reply": "2025-04-09T03:48:31.497672Z",
     "shell.execute_reply.started": "2025-04-09T03:48:24.089697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is already saved, so load it locally from disk\n",
      "tokenizer is already saved, so load it locally from disk\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_llm(\n",
    "    models_dir, \"model\", \"tokenizer\", \"blanchefort/rubert-base-cased-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5fc65",
   "metadata": {},
   "source": [
    "##### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17457f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"data\"\n",
    "dataset_name = \"main_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aadea067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:36.791558Z",
     "iopub.status.busy": "2025-04-09T03:48:36.791058Z",
     "iopub.status.idle": "2025-04-09T03:48:37.039327Z",
     "shell.execute_reply": "2025-04-09T03:48:37.038383Z",
     "shell.execute_reply.started": "2025-04-09T03:48:36.791514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset: pd.DataFrame = pd.read_csv(os.path.join(dataset_dir, dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df2a4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:38.883758Z",
     "iopub.status.busy": "2025-04-09T03:48:38.883331Z",
     "iopub.status.idle": "2025-04-09T03:48:39.576378Z",
     "shell.execute_reply": "2025-04-09T03:48:39.575437Z",
     "shell.execute_reply.started": "2025-04-09T03:48:38.883724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset['toxic'] = dataset['toxic'].astype(np.int32)\n",
    "dataset = dataset.rename(columns={\"toxic\": \"labels\"})\n",
    "dataset = dataset.drop_duplicates(subset=[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99b8860b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:50.354206Z",
     "iopub.status.busy": "2025-04-09T03:48:50.353872Z",
     "iopub.status.idle": "2025-04-09T03:48:50.364769Z",
     "shell.execute_reply": "2025-04-09T03:48:50.363760Z",
     "shell.execute_reply.started": "2025-04-09T03:48:50.354160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(dataset, random_state=42, test_size=0.2)\n",
    "test_df, val_df = train_test_split(test_df, random_state=42, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fa518a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:51.859070Z",
     "iopub.status.busy": "2025-04-09T03:48:51.858783Z",
     "iopub.status.idle": "2025-04-09T03:48:51.938471Z",
     "shell.execute_reply": "2025-04-09T03:48:51.937723Z",
     "shell.execute_reply.started": "2025-04-09T03:48:51.859048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "validation_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ec7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:53.531016Z",
     "iopub.status.busy": "2025-04-09T03:48:53.530698Z",
     "iopub.status.idle": "2025-04-09T03:48:56.164301Z",
     "shell.execute_reply": "2025-04-09T03:48:56.163351Z",
     "shell.execute_reply.started": "2025-04-09T03:48:53.530992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_tokenization(samples):\n",
    "    return tokenizer(\n",
    "        samples[\"comment\"], padding=False, truncation=False, return_tensors=\"np\"\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset_check_tokenized = train_dataset.map(check_tokenization, batched=True)\n",
    "validation_dataset_check_tokenized = validation_dataset.map(\n",
    "    check_tokenization, batched=True\n",
    ")\n",
    "test_dataset_check_tokenized = test_dataset.map(check_tokenization, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be7facf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:57.772907Z",
     "iopub.status.busy": "2025-04-09T03:48:57.772623Z",
     "iopub.status.idle": "2025-04-09T03:48:57.863254Z",
     "shell.execute_reply": "2025-04-09T03:48:57.862285Z",
     "shell.execute_reply.started": "2025-04-09T03:48:57.772886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_check_tokenized_df = train_dataset_check_tokenized.to_pandas()\n",
    "validation_dataset_check_tokenized_df = validation_dataset_check_tokenized.to_pandas()\n",
    "test_dataset_check_tokenized_df = test_dataset_check_tokenized.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0409b4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:48:59.804003Z",
     "iopub.status.busy": "2025-04-09T03:48:59.803676Z",
     "iopub.status.idle": "2025-04-09T03:48:59.946275Z",
     "shell.execute_reply": "2025-04-09T03:48:59.945585Z",
     "shell.execute_reply.started": "2025-04-09T03:48:59.803977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\"input_ids\", \"token_type_ids\", \"attention_mask\"]\n",
    "threshold = 512\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_dataset_check_tokenized_df[\n",
    "        train_dataset_check_tokenized_df[\"input_ids\"].apply(\n",
    "            lambda x: len(x) < threshold\n",
    "        )\n",
    "    ], preserve_index=False\n",
    ").remove_columns(columns_to_drop)\n",
    "\n",
    "validation_dataset = Dataset.from_pandas(\n",
    "    validation_dataset_check_tokenized_df[\n",
    "        validation_dataset_check_tokenized_df[\"input_ids\"].apply(\n",
    "            lambda x: len(x) < threshold\n",
    "        )\n",
    "    ],\n",
    "    preserve_index=False,\n",
    ").remove_columns(columns_to_drop)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_dataset_check_tokenized_df[\n",
    "        test_dataset_check_tokenized_df[\"input_ids\"].apply(lambda x: len(x) < threshold)\n",
    "    ],\n",
    "    preserve_index=False,\n",
    ").remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42cb5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:02.074778Z",
     "iopub.status.busy": "2025-04-09T03:49:02.074488Z",
     "iopub.status.idle": "2025-04-09T03:49:14.719745Z",
     "shell.execute_reply": "2025-04-09T03:49:14.719040Z",
     "shell.execute_reply.started": "2025-04-09T03:49:02.074756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "    return tokenizer(\n",
    "        samples[\"comment\"],\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset_tokenized = train_dataset.map(tokenize, batched=True)\n",
    "validation_dataset_tokenized = validation_dataset.map(tokenize, batched=True)\n",
    "test_dataset_tokenized = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34207b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:16.639714Z",
     "iopub.status.busy": "2025-04-09T03:49:16.639422Z",
     "iopub.status.idle": "2025-04-09T03:49:16.648007Z",
     "shell.execute_reply": "2025-04-09T03:49:16.647197Z",
     "shell.execute_reply.started": "2025-04-09T03:49:16.639694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_tokenized = train_dataset_tokenized.remove_columns([\"comment\"])\n",
    "validation_dataset_tokenized = validation_dataset_tokenized.remove_columns([\"comment\"])\n",
    "test_dataset_tokenized = test_dataset_tokenized.remove_columns([\"comment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c87bed",
   "metadata": {},
   "source": [
    "##### 3. Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c50d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:18.630629Z",
     "iopub.status.busy": "2025-04-09T03:49:18.630327Z",
     "iopub.status.idle": "2025-04-09T03:49:18.687905Z",
     "shell.execute_reply": "2025-04-09T03:49:18.687151Z",
     "shell.execute_reply.started": "2025-04-09T03:49:18.630600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1e6e5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:20.712018Z",
     "iopub.status.busy": "2025-04-09T03:49:20.711701Z",
     "iopub.status.idle": "2025-04-09T03:49:20.718318Z",
     "shell.execute_reply": "2025-04-09T03:49:20.717558Z",
     "shell.execute_reply.started": "2025-04-09T03:49:20.711994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_tokenized.set_format(type='torch',\n",
    "                                   columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "test_dataset_tokenized.set_format(type='torch',\n",
    "                                  columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "validation_dataset_tokenized.set_format(type='torch',\n",
    "                                        columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d4f89cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:24.079689Z",
     "iopub.status.busy": "2025-04-09T03:49:24.079405Z",
     "iopub.status.idle": "2025-04-09T03:49:24.083994Z",
     "shell.execute_reply": "2025-04-09T03:49:24.083076Z",
     "shell.execute_reply.started": "2025-04-09T03:49:24.079668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset_tokenized, shuffle=True, batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(validation_dataset_tokenized, shuffle=False, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset_tokenized, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aa67c8f-b432-474e-8895-771a1753648e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:27.803460Z",
     "iopub.status.busy": "2025-04-09T03:49:27.803105Z",
     "iopub.status.idle": "2025-04-09T03:49:29.880688Z",
     "shell.execute_reply": "2025-04-09T03:49:29.879996Z",
     "shell.execute_reply.started": "2025-04-09T03:49:27.803434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metric_names = [\"loss\", \"accuracy\", \"recall\", \"precision\"]\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "recall = evaluate.load('recall')\n",
    "precision = evaluate.load('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "004ce6c0-abf5-44bc-96f3-8cae974ad675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:32.501856Z",
     "iopub.status.busy": "2025-04-09T03:49:32.501555Z",
     "iopub.status.idle": "2025-04-09T03:49:32.515297Z",
     "shell.execute_reply": "2025-04-09T03:49:32.514213Z",
     "shell.execute_reply.started": "2025-04-09T03:49:32.501835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reduction = 'mean'\n",
    "cross_entropy = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "\n",
    "def calc_metrics(model, device: str, data_loader, metrics_dict: dict, enable_progress_bar: bool = True):\n",
    "    model.eval()\n",
    "    progress_bar = tqdm(range(len(data_loader))) if enable_progress_bar else None\n",
    "\n",
    "    for batch in data_loader:\n",
    "        with torch.no_grad():\n",
    "            batch[\"labels\"] = batch[\"labels\"].to(device)\n",
    "            batch[\"input_ids\"] = batch[\"input_ids\"].to(device)\n",
    "            batch[\"token_type_ids\"] = batch[\"token_type_ids\"].to(device)\n",
    "            batch[\"attention_mask\"] = batch[\"attention_mask\"].to(device)\n",
    "            outputs = model(**batch, return_dict=True)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            predictions = torch.argmax(predictions, dim=-1)\n",
    "\n",
    "            accuracy.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "            recall.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "            precision.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "            progress_bar.update(1)\n",
    "    metrics_dict['accuracy'].append([accuracy.compute()['accuracy']])\n",
    "    metrics_dict['recall'].append(recall.compute(average=None, zero_division=1)['recall'])\n",
    "    metrics_dict['precision'].append(precision.compute(average=None, zero_division=1)['precision'])\n",
    "\n",
    "\n",
    "def print_metrics(metrics:dict, mode:str, epoch: int):\n",
    "    if epoch > 0:\n",
    "        print(f\"epoch {epoch}:\")\n",
    "    print(f\"\\t{mode}:\")\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        formatted_values = \", \".join(f\"{round(value, 5)}\" for value in values[-1])\n",
    "        print(f\"\\t\\t{metric.capitalize()}: [{formatted_values}]\")\n",
    "\n",
    "\n",
    "def train_loop(model, device: str, data_loader, optimizer, train_loss, metrics_dict: dict,\n",
    "               progress_bar: tqdm=None, max_norm: float=1.0):\n",
    "    model.train(True)  \n",
    "    epoch_loss = 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch[\"labels\"] = batch[\"labels\"].to(device)\n",
    "        batch[\"input_ids\"] = batch[\"input_ids\"].to(device)\n",
    "        batch[\"token_type_ids\"] = batch[\"token_type_ids\"].to(device)\n",
    "        batch[\"attention_mask\"] = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(**batch, return_dict=True)  \n",
    "        loss = train_loss(outputs.logits, batch['labels'])\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        if progress_bar is not None:\n",
    "            progress_bar.update(1)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    calc_metrics(model, device, data_loader, metrics_dict)\n",
    "    metrics_dict['loss'].append([epoch_loss / num_batches]) \n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "def train(model, epoch_count: int, train_data_loader,\n",
    "          validation_dataloader, device: str, train_loss,\n",
    "          learning_rate: float, enable_progress_bar: bool=False):\n",
    "    model.to(device)\n",
    "    num_training_steps = epoch_count * len(train_data_loader)\n",
    "    progress_bar = tqdm(range(num_training_steps)) if enable_progress_bar else None\n",
    "\n",
    "    train_metrics_dict = {metric: list() for metric in metric_names}\n",
    "    validation_metrics_dict = {metric: list() for metric in metric_names}\n",
    "    validation_metrics_dict.pop('loss')\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        train_loop(model, device, train_data_loader, optimizer, train_loss, train_metrics_dict, progress_bar)\n",
    "        calc_metrics(model, device, validation_dataloader, validation_metrics_dict)\n",
    "        print_metrics(train_metrics_dict, \"train\", epoch + 1)\n",
    "        print_metrics(validation_metrics_dict, \"validation\", -1)\n",
    "\n",
    "    return train_metrics_dict, validation_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208d2f2-bfbd-4b1f-a065-7e42073d0752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T03:49:40.406198Z",
     "iopub.status.busy": "2025-04-09T03:49:40.405857Z",
     "iopub.status.idle": "2025-04-09T06:24:46.705564Z",
     "shell.execute_reply": "2025-04-09T06:24:46.704637Z",
     "shell.execute_reply.started": "2025-04-09T03:49:40.406148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epoch_count = 10\n",
    "learning_rate = 1e-6\n",
    "device = 'cuda'\n",
    "train_metrics, validation_metrics = train(model, epoch_count,\n",
    "                                          train_dataloader, validation_dataloader,\n",
    "                                          device, cross_entropy, learning_rate, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056972d-6e06-4150-aacc-67cc472866d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:51:02.646212Z",
     "iopub.status.busy": "2025-04-09T06:51:02.645834Z",
     "iopub.status.idle": "2025-04-09T06:51:03.836956Z",
     "shell.execute_reply": "2025-04-09T06:51:03.836266Z",
     "shell.execute_reply.started": "2025-04-09T06:51:02.646172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "model.save_pretrained(models_dir + \"tone-model-fine-tune-acc_\" + \"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c434e-b3e4-47e9-99e9-b97fc283745d",
   "metadata": {},
   "source": [
    "##### 4. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba1645-3a2e-48ef-bfdf-7a568ad6b4be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:52:20.386008Z",
     "iopub.status.busy": "2025-04-09T06:52:20.385711Z",
     "iopub.status.idle": "2025-04-09T06:52:20.589143Z",
     "shell.execute_reply": "2025-04-09T06:52:20.588461Z",
     "shell.execute_reply.started": "2025-04-09T06:52:20.385987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"tone-model-fine-tune-acc_final_model\"\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(os.path.join(models_dir, model_name), torchscript=True)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(os.path.join(models_dir, \"tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0ba2dc9-9e72-4fa0-97a6-6f6728b510b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T07:14:49.182127Z",
     "iopub.status.busy": "2025-04-09T07:14:49.181794Z",
     "iopub.status.idle": "2025-04-09T07:15:42.193681Z",
     "shell.execute_reply": "2025-04-09T07:15:42.192915Z",
     "shell.execute_reply.started": "2025-04-09T07:14:49.182105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [03:27<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest:\n",
      "\t\tAccuracy: [0.71076]\n",
      "\t\tRecall: [0.63451, 0.81161]\n",
      "\t\tPrecision: [0.81669, 0.62669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset_metrics_dict = {metric: list() for metric in metric_names}\n",
    "test_dataset_metrics_dict.pop('loss')\n",
    "fine_tuned_model.to(device)\n",
    "calc_metrics(fine_tuned_model, test_dataloader, test_dataset_metrics_dict)\n",
    "print_metrics(test_dataset_metrics_dict, 'test', -1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7075791,
     "sourceId": 11312906,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7075970,
     "sourceId": 11313140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7086218,
     "sourceId": 11328267,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
